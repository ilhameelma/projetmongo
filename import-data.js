// Script d'import des donnÃ©es JSON optimisÃ© pour le sharding composÃ©
print("DÃ©but de l'import des donnÃ©es avec optimisation sharding composÃ©...");

const db = db.getSiblingDB("air_quality_db");

// Fonction optimisÃ©e pour l'import avec vÃ©rification du sharding
function importJSONFile(filename, collectionName) {
    try {
        print(`\nğŸ“¥ Import de ${filename} dans ${collectionName}...`);
        const fileContent = cat(filename);
        
        // Parser le JSON ligne par ligne (format MongoDB export)
        const lines = fileContent.trim().split('\n');
        const documents = lines.map(line => JSON.parse(line));
        
        if (documents.length > 0) {
            print(`   ğŸ“Š ${documents.length} documents Ã  importer...`);
            
            // Import par lots pour meilleures performances
            const batchSize = 1000;
            let totalImported = 0;
            
            for (let i = 0; i < documents.length; i += batchSize) {
                const batch = documents.slice(i, i + batchSize);
                const result = db[collectionName].insertMany(batch);
                totalImported += result.insertedCount;
                
                if (i % 5000 === 0) {
                    print(`   âœ… ${totalImported}/${documents.length} documents importÃ©s...`);
                }
            }
            
            print(`   ğŸ‰ ${totalImported} documents importÃ©s dans ${collectionName}`);
            
            // VÃ©rification de la distribution aprÃ¨s import
            print(`   ğŸ“ˆ Distribution ${collectionName}:`);
            const stats = db[collectionName].stats();
            print(`      - Documents: ${stats.count}`);
            print(`      - Taille: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
            print(`      - Stockage: ${(stats.storageSize / 1024 / 1024).toFixed(2)} MB`);
            
            return totalImported;
        } else {
            print(`   âŒ Aucune donnÃ©e dans ${filename}`);
            return 0;
        }
    } catch (e) {
        print(`   âŒ Erreur import ${filename}: ${e}`);
        return 0;
    }
}

// Importer les donnÃ©es dans l'ordre optimal pour le sharding
try {
    print("ğŸš€ DÃ‰BUT DE L'IMPORT DES DONNÃ‰ES");
    print("=================================");
    
    let totalImported = 0;
    
    // 1. Stations d'abord (donnÃ©es de rÃ©fÃ©rence)
    totalImported += importJSONFile('/data/stations.json', 'stations');
    
    // 2. DonnÃ©es daily (air_quality)
    totalImported += importJSONFile('/data/air_quality.json', 'air_quality');
    
    // 3. DonnÃ©es horaires (city_hour et station_hour)
    totalImported += importJSONFile('/data/city_hour.json', 'city_hour');
    totalImported += importJSONFile('/data/station_hour.json', 'station_hour');
    
    print(`\nğŸ“ˆ IMPORT TERMINÃ‰: ${totalImported} documents au total`);
    
} catch (e) {
    print("âŒ Erreur lors de l'import: " + e);
}

// VÃ©rification finale de la distribution avec sharding composÃ©
print("\nğŸ“Š VÃ‰RIFICATION FINALE AVEC SHARDING COMPOSÃ‰:");
print("============================================");

const collections = ["air_quality", "city_hour", "station_hour", "stations"];

collections.forEach(collection => {
    print(`\nğŸ” Collection: ${collection}`);
    try {
        const count = db[collection].count();
        const stats = db[collection].stats();
        
        print(`   ğŸ“ Documents: ${count}`);
        print(`   ğŸ’¾ Taille donnÃ©es: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
        print(`   ğŸ’¿ Stockage: ${(stats.storageSize / 1024 / 1024).toFixed(2)} MB`);
        print(`   ğŸ“‹ Index: ${stats.nindexes} index`);
        
        // VÃ©rifier la distribution par clÃ© de sharding
        if (collection !== "stations") {
            const distinctKeys = db[collection].distinct(getShardKeyField(collection));
            print(`   ğŸ—‚ï¸  Valeurs distinctes (clÃ© primaire): ${distinctKeys.length}`);
        }
        
    } catch (e) {
        print(`   âŒ Erreur statistiques: ${e}`);
    }
});

// VÃ©rification du statut du sharding
print("\nğŸ¯ STATUT FINAL DU SHARDING COMPOSÃ‰:");
try {
    const finalStatus = sh.status();
    print("âœ… Sharding composÃ© actif et opÃ©rationnel");
    print("ğŸ“Š Distribution des chunks par collection:");
    
    const chunkStats = db.getSiblingDB("config").chunks.aggregate([
        { $group: { _id: "$ns", totalChunks: { $sum: 1 } } }
    ]).toArray();
    
    chunkStats.forEach(stat => {
        print(`   ğŸ“¦ ${stat._id}: ${stat.totalChunks} chunks`);
    });
    
} catch (e) {
    print("âŒ Erreur vÃ©rification statut sharding: " + e);
}

// Fonction utilitaire pour obtenir le champ principal de sharding
function getShardKeyField(collection) {
    const keys = {
        'air_quality': 'City',
        'city_hour': 'City', 
        'station_hour': 'StationId',
        'stations': 'StationId'
    };
    return keys[collection];
}

print("\nğŸ‰ SHARDING COMPOSÃ‰ APPLIQUÃ‰ AVEC SUCCÃˆS!");
print("=========================================");
print("âœ… DonnÃ©es importÃ©es et distribuÃ©es selon les clÃ©s composÃ©es");
print("âœ… Optimisation pour requÃªtes temporelles et gÃ©ographiques");
print("âœ… Cluster prÃªt pour l'application web");