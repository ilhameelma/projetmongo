#!/bin/bash

# Script d'initialisation du cluster MongoDB shard√© avec sharding compos√©
# Version corrig√©e pour les noms de conteneurs Docker Compose

set -e  # Arr√™ter le script en cas d'erreur

echo "üöÄ D√âMARRAGE DU CLUSTER MONGODB SHARD√â AVEC SHARDING COMPOS√â"
echo "=========================================================="
echo ""

# D√©finir les noms des conteneurs avec le pr√©fixe Docker Compose
COMPOSE_PROJECT_NAME="projetbasededonner_india"
CONFIG1="${COMPOSE_PROJECT_NAME}-mongodb-config-1-1"
CONFIG2="${COMPOSE_PROJECT_NAME}-mongodb-config-2-1"
CONFIG3="${COMPOSE_PROJECT_NAME}-mongodb-config-3-1"
SHARD1="${COMPOSE_PROJECT_NAME}-mongodb-shard1-1"
SHARD2="${COMPOSE_PROJECT_NAME}-mongodb-shard2-1"
SHARD3="${COMPOSE_PROJECT_NAME}-mongodb-shard3-1"
MONGOS="${COMPOSE_PROJECT_NAME}-mongos-1"

# Fonction pour afficher les messages de statut
log_info() {
    echo "üì¢ $1"
}

log_success() {
    echo "‚úÖ $1"
}

log_error() {
    echo "‚ùå $1"
}

log_step() {
    echo ""
    echo "üîπ $1"
}

# Fonction pour attendre qu'un conteneur soit pr√™t
wait_for_container() {
    local container=$1
    local max_attempts=30
    local attempt=1
    
    log_info "Attente que $container soit pr√™t..."
    
    while [ $attempt -le $max_attempts ]; do
        if docker exec $container mongosh --eval "db.adminCommand('ping')" > /dev/null 2>&1; then
            log_success "$container est pr√™t"
            return 0
        fi
        log_info "Tentative $attempt/$max_attempts - $container pas encore pr√™t..."
        sleep 2
        ((attempt++))
    done
    
    log_error "Timeout en attendant $container"
    return 1
}

log_step "1. D√âMARRAGE DES CONTENEURS DOCKER"
log_info "D√©marrage des services MongoDB..."

# Nettoyer les anciens conteneurs
docker-compose down > /dev/null 2>&1 || true

# D√©marrer les nouveaux conteneurs
docker-compose up -d

log_info "Attente du d√©marrage des services..."
sleep 5

# Attendre que tous les conteneurs soient pr√™ts
wait_for_container $CONFIG1
wait_for_container $CONFIG2
wait_for_container $CONFIG3
wait_for_container $SHARD1
wait_for_container $SHARD2
wait_for_container $SHARD3
wait_for_container $MONGOS

log_step "2. CONFIGURATION DES CONFIG SERVERS (REPLICA SET)"
log_info "Initialisation du replica set des config servers..."

docker exec -it $CONFIG1 mongosh --quiet --eval "
try {
    // Initialiser le replica set des config servers
    rs.initiate({
        _id: \"configrs\",
        configsvr: true,
        members: [
            { _id: 0, host: \"$CONFIG1:27017\" },
            { _id: 1, host: \"$CONFIG2:27017\" },
            { _id: 2, host: \"$CONFIG3:27017\" }
        ]
    });
    
    // Attendre que le replica set soit initialis√©
    var timeout = Date.now() + 30000;
    while(!rs.isMaster().ismaster && Date.now() < timeout) {
        sleep(1000);
    }
    
    if (rs.isMaster().ismaster) {
        print(\"‚úÖ Config servers replica set initialis√© et op√©rationnel\");
    } else {
        throw new Error(\"Timeout lors de l'initialisation du replica set\");
    }
} catch (e) {
    print(\"‚ùå Erreur configuration config servers: \" + e);
    throw e;
}
"

if [ $? -ne 0 ]; then
    log_error "√âchec de la configuration des config servers"
    exit 1
fi

log_info "Attente de la stabilisation du replica set (15 secondes)..."
sleep 15

log_step "3. CONFIGURATION DU SHARDING COMPOS√â VIA MONGOS"
log_info "Configuration du cluster shard√© avec sharding compos√©..."

docker exec -it $MONGOS mongosh --quiet --eval "
try {
    log_info = function(msg) { print('üì¢ ' + msg); }
    log_success = function(msg) { print('‚úÖ ' + msg); }
    log_error = function(msg) { print('‚ùå ' + msg); }
    
    log_info('Ajout des shards au cluster...');
    
    // Ajouter les shards au cluster
    sh.addShard(\"$SHARD1:27017\");
    sh.addShard(\"$SHARD2:27017\");
    sh.addShard(\"$SHARD3:27017\");
    
    log_success('3 shards ajout√©s au cluster');
    
    // Attendre que les shards soient reconnus
    sleep(5000);
    
    log_info('Activation du sharding pour la base de donn√©es...');
    
    // Activer le sharding pour la base de donn√©es
    sh.enableSharding(\"air_quality_db\");
    log_success('Sharding activ√© pour air_quality_db');
    
    log_info('Configuration du SHARDING COMPOS√â pour les collections...');
    
    // Cr√©er les collections et configurer le SHARDING COMPOS√â
    db = db.getSiblingDB(\"air_quality_db\");
    
    // City Hour - sharding compos√© City + Datetime
    db.createCollection(\"city_hour\");
    sh.shardCollection(\"air_quality_db.city_hour\", { 
        \"City\": 1, 
        \"Datetime\": 1
    });
    log_success('Sharding compos√© configur√© pour city_hour (City + Datetime)');
    
    // Air Quality - sharding compos√© City + Date  
    db.createCollection(\"air_quality\");
    sh.shardCollection(\"air_quality_db.air_quality\", { 
        \"City\": 1,
        \"Date\": 1
    });
    log_success('Sharding compos√© configur√© pour air_quality (City + Date)');
    
    // Station Hour - sharding compos√© StationId + Datetime
    db.createCollection(\"station_hour\");
    sh.shardCollection(\"air_quality_db.station_hour\", { 
        \"StationId\": 1,
        \"Datetime\": 1
    });
    log_success('Sharding compos√© configur√© pour station_hour (StationId + Datetime)');
    
    // Stations - sharding simple
    db.createCollection(\"stations\");
    sh.shardCollection(\"air_quality_db.stations\", { \"StationId\": 1 });
    log_success('Sharding simple configur√© pour stations (StationId)');
    
    log_info('Cr√©ation des index optimis√©s...');
    
    // Cr√©er les index pour optimiser les performances
    db.air_quality.createIndex({ \"City\": 1, \"Date\": -1 });
    db.air_quality.createIndex({ \"AQI_Bucket\": 1, \"City\": 1 });
    
    db.city_hour.createIndex({ \"City\": 1, \"Datetime\": -1 });
    db.city_hour.createIndex({ \"Datetime\": 1 });
    
    db.station_hour.createIndex({ \"StationId\": 1, \"Datetime\": -1 });
    db.station_hour.createIndex({ \"Datetime\": 1 });
    
    db.stations.createIndex({ \"City\": 1 });
    db.stations.createIndex({ \"State\": 1 });
    
    log_success('Index cr√©√©s pour optimiser les performances');
    
    // V√©rification finale
    log_info('V√©rification de la configuration...');
    
    const shardStatus = sh.status();
    if (shardStatus.shards && shardStatus.shards.length === 3) {
        log_success('Cluster shard√© configur√© avec succ√®s');
        
        // Afficher le r√©sum√©
        print('');
        print('üéâ R√âSUM√â DE LA CONFIGURATION SHARDING COMPOS√â:');
        print('==============================================');
        print('üèôÔ∏è  AIR_QUALITY:    { City: 1, Date: 1 }');
        print('üèôÔ∏è  CITY_HOUR:      { City: 1, Datetime: 1 }');
        print('üì° STATION_HOUR:    { StationId: 1, Datetime: 1 }');
        print('üè¢ STATIONS:        { StationId: 1 }');
        print('');
        print('üìç Mongos Router:   localhost:27017');
        print('üìä Base de donn√©es: air_quality_db');
        
    } else {
        throw new Error('Probl√®me avec la configuration du cluster');
    }
    
} catch (e) {
    log_error('Erreur configuration sharding: ' + e);
    throw e;
}
"

if [ $? -ne 0 ]; then
    log_error "√âchec de la configuration du sharding"
    exit 1
fi

log_step "4. V√âRIFICATION FINALE DU CLUSTER"
log_info "V√©rification du statut du cluster..."

docker exec -it $MONGOS mongosh --quiet --eval "
try {
    // V√©rifier le statut des shards
    const shardList = sh.status().shards;
    print('üìä SHARDS ACTIFS:');
    shardList.forEach((shard, index) => {
        print('   ' + (index + 1) + '. ' + shard._id + ' - ' + shard.host);
    });
    
    // V√©rifier les collections shard√©es
    const collections = db.getSiblingDB('config').collections.find({}).toArray();
    print('');
    print('üìÅ COLLECTIONS SHARD√âES:');
    collections.forEach(coll => {
        print('   üîë ' + coll._id);
        print('      Cl√©: ' + JSON.stringify(coll.key));
    });
    
    // V√©rifier la sant√© du cluster
    print('');
    print('‚ù§Ô∏è  SANT√â DU CLUSTER:');
    const adminDB = db.getSiblingDB('admin');
    const hostInfo = adminDB.runCommand({ hostInfo: 1 });
    print('   ‚úÖ Cluster op√©rationnel');
    print('   ‚úÖ Mongos router actif');
    print('   ‚úÖ ' + shardList.length + ' shards configur√©s');
    print('   ‚úÖ ' + collections.length + ' collections shard√©es');
    
} catch (e) {
    print('‚ùå Erreur v√©rification: ' + e);
}
"

log_step "5. PR√âPARATION POUR L'IMPORT DES DONN√âES"
log_info "Cr√©ation des dossiers pour l'import..."

# Cr√©er le dossier data dans le conteneur mongos si n√©cessaire
docker exec -it $MONGOS mkdir -p /data

log_success "Dossier /data cr√©√© dans le conteneur mongos"

echo ""
echo "üéâ CLUSTER MONGODB SHARD√â COMPOS√â INITIALIS√â AVEC SUCC√àS!"
echo "========================================================"
echo ""
echo "üìä R√âSUM√â DE LA CONFIGURATION:"
echo "   ‚úÖ 3 Config servers (replica set)"
echo "   ‚úÖ 3 Shards"
echo "   ‚úÖ 1 Router Mongos"
echo "   ‚úÖ Sharding compos√© activ√©"
echo ""
echo "üîß PROCHAINES √âTAPES:"
echo "   1. Copier les fichiers JSON dans le conteneur:"
echo "      docker cp air_quality.json $MONGOS:/data/"
echo "      docker cp city_hour.json $MONGOS:/data/"
echo "      docker cp station_hour.json $MONGOS:/data/"
echo "      docker cp stations.json $MONGOS:/data/"
echo ""
echo "   2. Importer les donn√©es:"
echo "      docker exec -it $MONGOS mongosh -f /data/import-data.js"
echo ""
echo "   3. D√©marrer l'application:"
echo "      npm install && npm start"
echo ""
echo "üìç INFORMATIONS DE CONNEXION:"
echo "   Host: localhost:27017"
echo "   Database: air_quality_db"
echo "   Via: Mongos Router"
echo ""
echo "‚ö° VOTRE CLUSTER SHARD√â COMPOS√â EST PR√äT!"